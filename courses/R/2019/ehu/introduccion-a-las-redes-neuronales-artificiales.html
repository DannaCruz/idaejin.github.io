<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 10 Introduccion a las redes neuronales artificiales | Introducción al software estadístico R</title>
  <meta name="description" content=" 10 Introduccion a las redes neuronales artificiales | Introducción al software estadístico R" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content=" 10 Introduccion a las redes neuronales artificiales | Introducción al software estadístico R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="idaejin/xxx" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 10 Introduccion a las redes neuronales artificiales | Introducción al software estadístico R" />
  
  
  

<meta name="author" content="Dae-Jin Lee &lt; dlee@bcamath.org &gt;" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="análisis-multivariante.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://idaejin.github.io/courses/R/2019/ehu/index.html">Curso de formación en R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Información y pre-requisitos</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introducción al software estadístico <code>R</code></a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#algunas-cuestiones-a-tener-en-cuenta-sobre-r"><i class="fa fa-check"></i><b>2.1</b> Algunas cuestiones a tener en cuenta sobre <code>R</code></a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#rstudio"><i class="fa fa-check"></i><b>2.2</b> Rstudio</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#instalar-un-paquete-de-r"><i class="fa fa-check"></i><b>2.3</b> Instalar un paquete de <code>R</code></a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#empezando-con-r"><i class="fa fa-check"></i><b>2.4</b> Empezando con <code>R</code></a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#cargar-librerías-en-r"><i class="fa fa-check"></i><b>2.5</b> Cargar librerías en <code>R</code></a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#lectura-de-datos"><i class="fa fa-check"></i><b>2.6</b> Lectura de datos</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#importar-datos"><i class="fa fa-check"></i><b>2.7</b> Importar datos</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#exportar-datos"><i class="fa fa-check"></i><b>2.8</b> Exportar datos</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#vectores"><i class="fa fa-check"></i><b>2.9</b> Vectores</a></li>
<li class="chapter" data-level="2.10" data-path="intro.html"><a href="intro.html#estadística-básica"><i class="fa fa-check"></i><b>2.10</b> Estadística básica</a></li>
<li class="chapter" data-level="2.11" data-path="intro.html"><a href="intro.html#vectores-caracteres-y-variables-factor"><i class="fa fa-check"></i><b>2.11</b> Vectores caracteres y variables factor</a></li>
<li class="chapter" data-level="2.12" data-path="intro.html"><a href="intro.html#data-frames"><i class="fa fa-check"></i><b>2.12</b> Data frames</a><ul>
<li class="chapter" data-level="2.12.1" data-path="intro.html"><a href="intro.html#trabajando-con-data-frames"><i class="fa fa-check"></i><b>2.12.1</b> Trabajando con data frames</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="intro.html"><a href="intro.html#vectores-lógicos"><i class="fa fa-check"></i><b>2.13</b> Vectores lógicos</a></li>
<li class="chapter" data-level="2.14" data-path="intro.html"><a href="intro.html#trabajando-con-vectores"><i class="fa fa-check"></i><b>2.14</b> Trabajando con vectores</a></li>
<li class="chapter" data-level="2.15" data-path="intro.html"><a href="intro.html#matrices-y-arrays"><i class="fa fa-check"></i><b>2.15</b> Matrices y arrays</a></li>
<li class="chapter" data-level="2.16" data-path="intro.html"><a href="intro.html#factores"><i class="fa fa-check"></i><b>2.16</b> Factores</a></li>
<li class="chapter" data-level="2.17" data-path="intro.html"><a href="intro.html#indexando-vectores-con-condiciones-lógicas"><i class="fa fa-check"></i><b>2.17</b> Indexando vectores con condiciones lógicas</a></li>
<li class="chapter" data-level="2.18" data-path="intro.html"><a href="intro.html#valores-faltantes"><i class="fa fa-check"></i><b>2.18</b> Valores faltantes</a></li>
<li class="chapter" data-level="2.19" data-path="intro.html"><a href="intro.html#trabajando-con-data-frames-1"><i class="fa fa-check"></i><b>2.19</b> Trabajando con data frames</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic.html"><a href="basic.html"><i class="fa fa-check"></i><b>3</b> Análisis de datos básico en <code>R</code></a><ul>
<li class="chapter" data-level="3.1" data-path="basic.html"><a href="basic.html#gráficos-sencillos"><i class="fa fa-check"></i><b>3.1</b> Gráficos sencillos</a></li>
<li class="chapter" data-level="3.2" data-path="basic.html"><a href="basic.html#scatterplots"><i class="fa fa-check"></i><b>3.2</b> Scatterplots</a></li>
<li class="chapter" data-level="3.3" data-path="basic.html"><a href="basic.html#más-opciones-gráficas"><i class="fa fa-check"></i><b>3.3</b> Más opciones gráficas</a></li>
<li class="chapter" data-level="3.4" data-path="basic.html"><a href="basic.html#tablas-de-clasificación-cruzada-o-de-contigencia"><i class="fa fa-check"></i><b>3.4</b> Tablas de clasificación cruzada o de contigencia</a></li>
<li class="chapter" data-level="3.5" data-path="basic.html"><a href="basic.html#datos-cualitativos"><i class="fa fa-check"></i><b>3.5</b> Datos cualitativos</a></li>
<li class="chapter" data-level="3.6" data-path="basic.html"><a href="basic.html#datos-cuantitativos"><i class="fa fa-check"></i><b>3.6</b> Datos cuantitativos</a><ul>
<li class="chapter" data-level="3.6.1" data-path="basic.html"><a href="basic.html#distribuciones-de-frecuencias"><i class="fa fa-check"></i><b>3.6.1</b> Distribuciones de frecuencias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html"><i class="fa fa-check"></i><b>4</b> Introducción a la programación básica con <code>R</code></a><ul>
<li class="chapter" data-level="4.1" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#condicionales"><i class="fa fa-check"></i><b>4.1</b> Condicionales</a></li>
<li class="chapter" data-level="4.2" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#operadores-lógicos"><i class="fa fa-check"></i><b>4.2</b> Operadores Lógicos</a></li>
<li class="chapter" data-level="4.3" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#if"><i class="fa fa-check"></i><b>4.3</b> <code>if</code></a></li>
<li class="chapter" data-level="4.4" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#ifelse"><i class="fa fa-check"></i><b>4.4</b> <code>ifelse</code></a></li>
<li class="chapter" data-level="4.5" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#loops-o-bucles"><i class="fa fa-check"></i><b>4.5</b> Loops o Bucles</a><ul>
<li class="chapter" data-level="4.5.1" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#for"><i class="fa fa-check"></i><b>4.5.1</b> <code>for</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#while"><i class="fa fa-check"></i><b>4.5.2</b> <code>while</code></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#famila-de-funciones-apply"><i class="fa fa-check"></i><b>4.6</b> Famila de funciones <code>apply</code></a></li>
<li class="chapter" data-level="4.7" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#other-loops"><i class="fa fa-check"></i><b>4.7</b> Other Loops</a></li>
<li class="chapter" data-level="4.8" data-path="introducción-a-la-programación-básica-con-r.html"><a href="introducción-a-la-programación-básica-con-r.html#improving-speed-performance-of-loops"><i class="fa fa-check"></i><b>4.8</b> Improving Speed Performance of Loops</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html"><i class="fa fa-check"></i><b>5</b> Distribuciones de probabilidad en R</a><ul>
<li class="chapter" data-level="5.1" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#distribución-binomial-binnp"><i class="fa fa-check"></i><b>5.1</b> Distribución binomial <span class="math inline">\(Bin(n,p)\)</span></a></li>
<li class="chapter" data-level="5.2" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#distribución-de-poisson-poislambda"><i class="fa fa-check"></i><b>5.2</b> Distribución de Poisson <span class="math inline">\(Pois(\lambda)\)</span></a><ul>
<li class="chapter" data-level="5.2.1" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#aproximación-de-binomial-como-poisson"><i class="fa fa-check"></i><b>5.2.1</b> Aproximación de Binomial como Poisson</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#distribution-exponencial-explambda"><i class="fa fa-check"></i><b>5.3</b> Distribution Exponencial <span class="math inline">\(Exp(\lambda)\)</span></a></li>
<li class="chapter" data-level="5.4" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#distribution-normal-mathcalnmusigma2"><i class="fa fa-check"></i><b>5.4</b> Distribution Normal <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="distribuciones-de-probabilidad-en-r.html"><a href="distribuciones-de-probabilidad-en-r.html#distribución-uniforme-uab"><i class="fa fa-check"></i><b>5.5</b> Distribución Uniforme <span class="math inline">\(U(a,b)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html"><i class="fa fa-check"></i><b>6</b> Modelos lineales y análisis de la varianza</a><ul>
<li class="chapter" data-level="6.1" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#principios-de-la-modelización-estadística"><i class="fa fa-check"></i><b>6.1</b> Principios de la modelización estadística</a><ul>
<li class="chapter" data-level="6.1.1" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#identificar-y-caracterizar-variables"><i class="fa fa-check"></i><b>6.1.1</b> Identificar y Caracterizar Variables</a></li>
<li class="chapter" data-level="6.1.2" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#tipos-de-variables-y-tipo-de-modelo"><i class="fa fa-check"></i><b>6.1.2</b> Tipos de variables y tipo de modelo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#el-modelo-lineal-general"><i class="fa fa-check"></i><b>6.2</b> El modelo lineal general</a></li>
<li class="chapter" data-level="6.3" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#definición-de-modelos-en-r"><i class="fa fa-check"></i><b>6.3</b> Definición de modelos en <code>R</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#ejemplo-datos-de-precios-de-viviendas-en-boston"><i class="fa fa-check"></i><b>6.3.1</b> Ejemplo: Datos de precios de viviendas en Boston</a></li>
<li class="chapter" data-level="6.3.2" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#regresión-lineal-múltiple"><i class="fa fa-check"></i><b>6.3.2</b> Regresión lineal múltiple</a></li>
<li class="chapter" data-level="6.3.3" data-path="modelos-lineales-y-análisis-de-la-varianza.html"><a href="modelos-lineales-y-análisis-de-la-varianza.html#modelos-con-interacciones"><i class="fa fa-check"></i><b>6.3.3</b> Modelos con interacciones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>7</b> Regresión logística</a><ul>
<li class="chapter" data-level="7.1" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-datos-de-crédito-en-alemania-credit-scoring"><i class="fa fa-check"></i><b>7.1</b> Ejemplo: Datos de crédito en Alemania (<em>Credit scoring</em>)</a></li>
<li class="chapter" data-level="7.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-predecir-el-salario-de-los-trabajadores"><i class="fa fa-check"></i><b>7.2</b> Ejemplo: Predecir el salario de los trabajadores</a></li>
<li class="chapter" data-level="7.3" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-datos-de-los-supervivientes-del-titanic"><i class="fa fa-check"></i><b>7.3</b> Ejemplo: Datos de los supervivientes del Titanic</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html"><i class="fa fa-check"></i><b>8</b> Modelos Aditivos Generalizados</a><ul>
<li class="chapter" data-level="8.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#suavizado"><i class="fa fa-check"></i><b>8.1</b> Suavizado</a><ul>
<li class="chapter" data-level="8.1.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#regresión-polinomial"><i class="fa fa-check"></i><b>8.1.1</b> Regresión polinomial</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#gams"><i class="fa fa-check"></i><b>8.2</b> GAMs</a><ul>
<li class="chapter" data-level="8.2.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#ejemplo-salarios"><i class="fa fa-check"></i><b>8.2.1</b> Ejemplo: Salarios</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelos-semi-paramétricos"><i class="fa fa-check"></i><b>8.3</b> Modelos semi-paramétricos</a><ul>
<li class="chapter" data-level="8.3.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#ejemplo"><i class="fa fa-check"></i><b>8.3.1</b> Ejemplo:</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#ejemplo-calidad-del-aire"><i class="fa fa-check"></i><b>8.4</b> Ejemplo: Calidad del Aire</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="análisis-multivariante.html"><a href="análisis-multivariante.html"><i class="fa fa-check"></i><b>9</b> Análisis multivariante</a><ul>
<li class="chapter" data-level="9.1" data-path="análisis-multivariante.html"><a href="análisis-multivariante.html#análisis-de-componentes-principales"><i class="fa fa-check"></i><b>9.1</b> Análisis de Componentes Principales</a></li>
<li class="chapter" data-level="9.2" data-path="análisis-multivariante.html"><a href="análisis-multivariante.html#k-medias"><i class="fa fa-check"></i><b>9.2</b> K-medias</a></li>
<li class="chapter" data-level="9.3" data-path="análisis-multivariante.html"><a href="análisis-multivariante.html#cluster-jerárquico"><i class="fa fa-check"></i><b>9.3</b> Cluster jerárquico</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html"><i class="fa fa-check"></i><b>10</b> Introduccion a las redes neuronales artificiales</a><ul>
<li class="chapter" data-level="10.1" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#arquitecturas-de-las-rna"><i class="fa fa-check"></i><b>10.1</b> Arquitecturas de las RNA</a></li>
<li class="chapter" data-level="10.2" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#ejemplo-datos-boston-housing"><i class="fa fa-check"></i><b>10.2</b> Ejemplo: datos Boston housing</a></li>
<li class="chapter" data-level="10.3" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#ajuste-de-la-red-neuronal"><i class="fa fa-check"></i><b>10.3</b> Ajuste de la red neuronal</a></li>
<li class="chapter" data-level="10.4" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#predicción-con-una-red-neuronal"><i class="fa fa-check"></i><b>10.4</b> Predicción con una red neuronal</a></li>
<li class="chapter" data-level="10.5" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#evaluando-la-predicción-mediante-validación-cruzada"><i class="fa fa-check"></i><b>10.5</b> Evaluando la predicción mediante validación cruzada</a><ul>
<li class="chapter" data-level="10.5.1" data-path="introduccion-a-las-redes-neuronales-artificiales.html"><a href="introduccion-a-las-redes-neuronales-artificiales.html#comparación-de-modelos-rna"><i class="fa fa-check"></i><b>10.5.1</b> Comparación de modelos RNA</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="http://idaejin.github.io/" target="blank">Mi página personal</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción al software estadístico <code>R</code></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduccion-a-las-redes-neuronales-artificiales" class="section level1">
<h1><span class="header-section-number"> 10</span> Introduccion a las redes neuronales artificiales</h1>
<p>En esta sección describimos una clase de métodos de aprendizaje que se desarrollaron por separado en diferentes campos: estadística e inteligencia artificial basadas en modelos esencialmente idénticos.</p>
<p>Las redes neuronales artificiales se inspiran en el comportamiento conocido del cerebro humano (principalmente el referido a las neuronas y sus conexiones), trata de crear modelos artificiales que solucionen problemas difíciles de resolver mediante técnicas algorítmicas convencionales.</p>
<p>La idea central es extraer las combinaciones lineales de las variables de entrada como características derivadas y, a continuación, modelar el objetivo como una función no lineal de estas características. El resultado es un poderoso método de aprendizaje, con amplias aplicaciones en muchos campos.</p>
<p>la neurona artificial pretende mimetizar las características más importantes de la neurona biólogica. En general, recibe las señales de entrada de las neuronas v ecinas ponderadas por los pesos de las conexiones. La suma de estas señales ponderadas proporciona la entrada total o neta de la neurona y, mediante la aplicación de una función matemática - denominada función de salida - , sobre la entrada neta, se calcula un valor de salida, el cual es enviado a otras neuronas.</p>
<div class="figure">
<img src="figures/neurona.png" alt="Estructura general de una neurona biológica." />
<p class="caption"><em>Estructura general de una neurona biológica.</em></p>
</div>
<p>Tanto los valores de entrada a la neurona como su salida pueden ser señales excitatorias (cuando el valor es positivo) o inhibitorias (cuando el valor es negativo).</p>
<div class="figure">
<img src="figures/neurona_artificial.png" alt="Funcionamiento general de una neurona artificial." />
<p class="caption"><em>Funcionamiento general de una neurona artificial.</em></p>
</div>
<div id="arquitecturas-de-las-rna" class="section level2">
<h2><span class="header-section-number">10.1</span> Arquitecturas de las RNA</h2>
<p>Las neuronas que componen una RNA se organizan de forma jerárquica formando capas. Una capa o nivel es un conjunto de neuronas cuyas entradas de información provienen de la misma fuente (que puede ser otra capa de neuronas) y cuyas salidas de información se dirigen al mismo destino (que puede ser otra capa de neuronas). En este sentido, se distinguen tres tipos de capas: la capa de entrada recibe la información del exterior; la o las capas ocultas son aquellas cuyas entradas y salidas se encuentran dentro del sistema y, por tanto, no tienen contacto con el exterior; por último, la capa de salida envía la respuesta de la red al exterior.</p>
<p>En función de la organización de las neuronas en la red formando capas o agrupaciones podemos encontrarnos con dos tipos de arquitecturas básicas: redes multicapa (multi-layer) y redes monocapa (single-layer).</p>
</div>
<div id="ejemplo-datos-boston-housing" class="section level2">
<h2><span class="header-section-number">10.2</span> Ejemplo: datos Boston housing</h2>
<p>Vamos a utilizar el conjunto de datos de <code>Boston</code> en el paquete <code>MASS</code>. Recordemos que el conjunto de datos de <code>Boston</code> es una colección de datos sobre valores de vivienda en los suburbios de Boston. Nuestro objetivo es predecir el valor medio de las viviendas ocupadas por sus propietarios (`medv) utilizando todas las demás variables continuas disponibles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">500</span>)
<span class="kw">library</span>(MASS)
data &lt;-<span class="st"> </span>Boston</code></pre></div>
<p>Primero tenemos que comprobar que no hay datos faltantes, de lo contrario tenemos que arreglar el conjunto de datos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apply</span>(data,<span class="dv">2</span>,<span class="cf">function</span>(x) <span class="kw">sum</span>(<span class="kw">is.na</span>(x)))</code></pre></div>
<pre><code>##    crim      zn   indus    chas     nox      rm     age     dis     rad 
##       0       0       0       0       0       0       0       0       0 
##     tax ptratio   black   lstat    medv 
##       0       0       0       0       0</code></pre>
<p>Hemos comprobado que no hay datos faltantes (<code>NA</code>). Procedemos dividiendo aleatoriamente los datos en un conjunto de entrenamiento y un conjunto de prueba, luego ajustamos un modelo de regresión lineal y lo probamos en el conjunto de prueba. Nótese que usamos la función <code>glm()</code> en lugar de la función <code>lm()</code> esto será útil más tarde al validar el modelo lineal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data),<span class="kw">round</span>(<span class="fl">0.75</span><span class="op">*</span><span class="kw">nrow</span>(data)))
train &lt;-<span class="st"> </span>data[index,]
test &lt;-<span class="st"> </span>data[<span class="op">-</span>index,]
lm.fit &lt;-<span class="st"> </span><span class="kw">glm</span>(medv<span class="op">~</span>., <span class="dt">data=</span>train)
<span class="kw">summary</span>(lm.fit)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = medv ~ ., data = train)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -14.9143   -2.8607   -0.5244    1.5242   25.0004  
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  43.469681   6.099347   7.127 5.50e-12 ***
## crim         -0.105439   0.057095  -1.847 0.065596 .  
## zn            0.044347   0.015974   2.776 0.005782 ** 
## indus         0.024034   0.071107   0.338 0.735556    
## chas          2.596028   1.089369   2.383 0.017679 *  
## nox         -22.336623   4.572254  -4.885 1.55e-06 ***
## rm            3.538957   0.472374   7.492 5.15e-13 ***
## age           0.016976   0.015088   1.125 0.261291    
## dis          -1.570970   0.235280  -6.677 9.07e-11 ***
## rad           0.400502   0.085475   4.686 3.94e-06 ***
## tax          -0.015165   0.004599  -3.297 0.001072 ** 
## ptratio      -1.147046   0.155702  -7.367 1.17e-12 ***
## black         0.010338   0.003077   3.360 0.000862 ***
## lstat        -0.524957   0.056899  -9.226  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 23.26491)
## 
##     Null deviance: 33642  on 379  degrees of freedom
## Residual deviance:  8515  on 366  degrees of freedom
## AIC: 2290
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> pr.lm &lt;-<span class="st"> </span><span class="kw">predict</span>(lm.fit,test)
MSE.lm &lt;-<span class="st"> </span><span class="kw">sum</span>((pr.lm <span class="op">-</span><span class="st"> </span>test<span class="op">$</span>medv)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">nrow</span>(test)</code></pre></div>
<p>La función <code>sample(x,size)</code> simplemente produce un vector del tamaño especificado de muestras seleccionadas aleatoriamente desde el vector x. Por defecto el muestreo es sin reemplazo: el índice es esencialmente un vector aleatorio de muestras.</p>
<p>Como se trata de un problema de regresión, vamos a utilizar el error cuadrático medio (ECM) como medida de lo lejos que están nuestras predicciones de los datos reales.</p>
</div>
<div id="ajuste-de-la-red-neuronal" class="section level2">
<h2><span class="header-section-number">10.3</span> Ajuste de la red neuronal</h2>
<p>Antes de entrenar una red neural, es necesario hacer algún paso previo. Como primer paso, vamos a abordar el preprocesamiento de datos.</p>
<ul>
<li><p>Es una buena práctica normalizar los datos antes de entrenar una red neuronal.</p></li>
<li><p>Se pueden elegir diferentes métodos para escalar los datos (normalización-z, escala min-max, etc…).</p></li>
<li><p>Elegiremos el método min-max y escalaremos los datos en el intervalo <span class="math inline">\([0,1]\)</span>. Por lo general, la escala en los intervalos <span class="math inline">\([0,1]\)</span> ó <span class="math inline">\([-1,1]\)</span> tiende a dar mejores resultados.</p></li>
<li><p>Por lo tanto, escalamos y dividimos los datos antes de seguir adelante:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">maxs &lt;-<span class="st"> </span><span class="kw">apply</span>(data, <span class="dv">2</span>, max)
mins &lt;-<span class="st"> </span><span class="kw">apply</span>(data, <span class="dv">2</span>, min)

scaled &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">scale</span>(data, <span class="dt">center =</span> mins, <span class="dt">scale =</span> maxs <span class="op">-</span><span class="st"> </span>mins))

train_ &lt;-<span class="st"> </span>scaled[index,]
 test_ &lt;-<span class="st"> </span>scaled[<span class="op">-</span>index,]</code></pre></div>
<p>No hay una regla fija en cuanto a cuántas capas y neuronas usar, aunque hay varias reglas generales más o menos aceptadas. Normalmente, si es necesario, una capa oculta es suficiente para un gran número de aplicaciones.</p>
<p>En cuanto al número de neuronas, debería estar entre el tamaño de la capa de entrada y el tamaño de la capa de salida, normalmente 2/3 del tamaño de entrada. No hay garantía de que ninguna de estas reglas se ajuste mejor a su modelo de modo que es recomendable probar con diferentes combinaciones.</p>
<p>Para este ejemplo, vamos a usar 2 capas ocultas con esta configuración: <code>13:5:3:1</code>.</p>
<ul>
<li><p>La capa de entrada tiene 13 entradas,</p></li>
<li><p>las dos capas ocultas tienen 5 y 3 neuronas y</p></li>
<li><p>la capa de salida tiene, por supuesto, una sola salida ya que estamos haciendo regresión.</p></li>
</ul>
<p>Vamos a entrar en la red:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(neuralnet)
n &lt;-<span class="st"> </span><span class="kw">names</span>(train_)
f &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;medv ~&quot;</span>, <span class="kw">paste</span>(n[<span class="op">!</span>n <span class="op">%in%</span><span class="st"> &quot;medv&quot;</span>], <span class="dt">collapse =</span> <span class="st">&quot; + &quot;</span>)))
nn &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(f,<span class="dt">data=</span>train_,<span class="dt">hidden=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>),<span class="dt">linear.output=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><strong>Nota:</strong></p>
<ul>
<li><p>La expresión <code>y~.</code> no es aceptada por la función <code>neuralnet()</code>.</p></li>
<li><p>El argumento oculto acepta un vector con el número de neuronas para cada capa oculta, mientras que el argumento <code>linear.output</code> se usa para especificar si queremos hacer una regresión <code>linear.output=TRUE</code> o clasificación <code>linear.output=FALSE</code>.</p></li>
</ul>
<p>La librería <code>neuralnet</code> proporciona una buena herramienta para representar gráficamente el modelo con los pesos en cada conexión:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(nn)</code></pre></div>
<p>Las líneas negras muestran las conexiones entre cada capa y los pesos de cada conexión, mientras que las líneas azules muestran el término de sesgo añadido en cada paso. El sesgo puede ser pensado como el intercepto de un modelo lineal.</p>
<p>La red neuronal es esencialmente una caja negra, por lo que no podemos decir mucho sobre el ajuste, los pesos y el modelo. Basta decir que el algoritmo de entrenamiento ha convergido y por lo tanto el modelo está listo para ser utilizado.</p>
</div>
<div id="predicción-con-una-red-neuronal" class="section level2">
<h2><span class="header-section-number">10.4</span> Predicción con una red neuronal</h2>
<p>Ahora podemos tratar de predecir los valores para el equipo de prueba y calcular el ECM. Recuerda que la red producirá una predicción normalizada, por lo que necesitamos reducirla para hacer una comparación significativa (o simplemente una predicción simple).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(neuralnet)
pr.nn &lt;-<span class="st"> </span>neuralnet<span class="op">::</span><span class="kw">compute</span>(nn,test_[,<span class="dv">1</span><span class="op">:</span><span class="dv">13</span>])

pr.nn_ &lt;-<span class="st"> </span>pr.nn<span class="op">$</span>net.result<span class="op">*</span>(<span class="kw">max</span>(data<span class="op">$</span>medv)<span class="op">-</span><span class="kw">min</span>(data<span class="op">$</span>medv))<span class="op">+</span><span class="kw">min</span>(data<span class="op">$</span>medv)
test.r &lt;-<span class="st"> </span>(test_<span class="op">$</span>medv)<span class="op">*</span>(<span class="kw">max</span>(data<span class="op">$</span>medv)<span class="op">-</span><span class="kw">min</span>(data<span class="op">$</span>medv))<span class="op">+</span><span class="kw">min</span>(data<span class="op">$</span>medv)

MSE.nn &lt;-<span class="st"> </span><span class="kw">sum</span>((test.r <span class="op">-</span><span class="st"> </span>pr.nn_)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">nrow</span>(test_)
MSE.nn</code></pre></div>
<pre><code>## [1] 15.75184</code></pre>
<p>Podemos ahora comparar los dos ECM:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">paste</span>(MSE.lm,MSE.nn))</code></pre></div>
<pre><code>## [1] &quot;21.6297593507225 15.7518370200153&quot;</code></pre>
<p>Aparentemente la red neuronal está haciendo un mejor trabajo que el modelo lineal en la predicción de <code>medv</code>. Una vez más, hay que tener cuidado porque este resultado depende de la división de prueba de entrenamiento realizada anteriormente.</p>
<p>A continuación, vamos a realizar una rápida validación cruzada para tener más confianza en los resultados.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))

<span class="kw">plot</span>(test<span class="op">$</span>medv,pr.nn_,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>,<span class="dt">main=</span><span class="st">&#39;Real vs predicted NN&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">cex=</span><span class="fl">0.7</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&#39;bottomright&#39;</span>,<span class="dt">legend=</span><span class="st">&#39;NN&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>)

<span class="kw">plot</span>(test<span class="op">$</span>medv,pr.lm,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">main=</span><span class="st">&#39;Real vs predicted lm&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>, <span class="dt">cex=</span><span class="fl">0.7</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&#39;bottomright&#39;</span>,<span class="dt">legend=</span><span class="st">&#39;LM&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">cex=</span>.<span class="dv">95</span>)</code></pre></div>
<p><img src="cursoR_files/figure-html/pplot%20-1.png" width="672" /></p>
<p>Inspeccionando visualmente podemos ver que las predicciones hechas por la red neural están (en general) más concentradas alrededor de la línea (una alineación perfecta con la línea indicaría un ECM de 0 y por lo tanto una predicción perfecta ideal) que las hechas por el modelo lineal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(test<span class="op">$</span>medv,pr.nn_,<span class="dt">col=</span><span class="st">&#39;red&#39;</span>,<span class="dt">main=</span><span class="st">&#39;Real vs predicted NN&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">cex=</span><span class="fl">0.7</span>)
<span class="kw">points</span>(test<span class="op">$</span>medv,pr.lm,<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">cex=</span><span class="fl">0.7</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&#39;bottomright&#39;</span>,<span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&#39;NN&#39;</span>,<span class="st">&#39;LM&#39;</span>),<span class="dt">pch=</span><span class="dv">18</span>,<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;red&#39;</span>,<span class="st">&#39;blue&#39;</span>))</code></pre></div>
<p><img src="cursoR_files/figure-html/ppo-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="evaluando-la-predicción-mediante-validación-cruzada" class="section level2">
<h2><span class="header-section-number">10.5</span> Evaluando la predicción mediante validación cruzada</h2>
<p>La validación cruzada es otro paso muy importante en la construcción de modelos predictivos. Aunque existen diferentes tipos de métodos de validación cruzada, la idea básica es repetir el proceso siguiente varias veces:</p>
<p><strong>División Entrenamiento-Prueba:</strong></p>
<ul>
<li>Realizar la división entre muestra de entrenamiento-prueba.</li>
<li>Ajustar el modelos al conjunto de entrenamiento.</li>
<li>Comprobar el modelo en el conjunto de prueba.</li>
<li>Calcular el error de predicción.</li>
<li>Repetir el proceso <span class="math inline">\(K\)</span> veces.</li>
</ul>
<p>Luego, calculando el error promedio, podemos hacernos una idea de cómo le está yendo al modelo.</p>
<p>Vamos a implementar una validación cruzada usando un bucle para la red neuronal y la función <code>cv.glm()</code> en el paquete <code>boot</code> para el modelo lineal. Para <span class="math inline">\(K=10\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(boot)
<span class="kw">set.seed</span>(<span class="dv">200</span>)
lm.fit &lt;-<span class="st"> </span><span class="kw">glm</span>(medv<span class="op">~</span>.,<span class="dt">data=</span>data)
<span class="kw">cv.glm</span>(data,lm.fit,<span class="dt">K=</span><span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 23.8356</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">450</span>)
cv.error &lt;-<span class="st"> </span><span class="ot">NULL</span>
k &lt;-<span class="st"> </span><span class="dv">10</span>


<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k){
    index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data),<span class="kw">round</span>(<span class="fl">0.9</span><span class="op">*</span><span class="kw">nrow</span>(data)))
    train.cv &lt;-<span class="st"> </span>scaled[index,]
    test.cv &lt;-<span class="st"> </span>scaled[<span class="op">-</span>index,]

    nn &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(f,<span class="dt">data=</span>train.cv,<span class="dt">hidden=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">2</span>),<span class="dt">linear.output=</span>T)

    pr.nn &lt;-<span class="st"> </span>neuralnet<span class="op">::</span><span class="kw">compute</span>(nn,test.cv[,<span class="dv">1</span><span class="op">:</span><span class="dv">13</span>])
    pr.nn &lt;-<span class="st"> </span>pr.nn<span class="op">$</span>net.result<span class="op">*</span>(<span class="kw">max</span>(data<span class="op">$</span>medv)<span class="op">-</span><span class="kw">min</span>(data<span class="op">$</span>medv))<span class="op">+</span><span class="kw">min</span>(data<span class="op">$</span>medv)

    test.cv.r &lt;-<span class="st"> </span>(test.cv<span class="op">$</span>medv)<span class="op">*</span>(<span class="kw">max</span>(data<span class="op">$</span>medv)<span class="op">-</span><span class="kw">min</span>(data<span class="op">$</span>medv))<span class="op">+</span><span class="kw">min</span>(data<span class="op">$</span>medv)

    cv.error[i] &lt;-<span class="st"> </span><span class="kw">sum</span>((test.cv.r <span class="op">-</span><span class="st"> </span>pr.nn)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">nrow</span>(test.cv)

}</code></pre></div>
<p>Calculamos el ECM promedio y graficamos los resultados como una gráfica de caja.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(cv.error)</code></pre></div>
<pre><code>## [1] 10.32698</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv.error</code></pre></div>
<pre><code>##  [1] 17.640653  6.310575 15.769519  5.730131 10.520947  6.121161  6.389967
##  [8]  8.004786 17.369282  9.412778</code></pre>
<p>Boxplot</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxplot</span>(cv.error,<span class="dt">xlab=</span><span class="st">&#39;MSE CV&#39;</span>,<span class="dt">col=</span><span class="st">&#39;cyan&#39;</span>,
        <span class="dt">border=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">names=</span><span class="st">&#39;CV error (MSE)&#39;</span>,
        <span class="dt">main=</span><span class="st">&#39;CV error (MSE) for NN&#39;</span>,<span class="dt">horizontal=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><img src="cursoR_files/figure-html/bb-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Como se puede ver, la media del ECM de la red neural (10.33) es inferior al del modelo lineal, aunque parece haber cierto grado de variación en laos ECMs de la validación cruzada. Esto puede depender de la división de los datos o de la inicialización aleatoria de los pesos en la red neuronal. Al ejecutar la simulación en diferentes momentos con diferentes semillas, puede obtener una estimación puntual más precisa para el ECM medio.</p>
<div id="comparación-de-modelos-rna" class="section level3">
<h3><span class="header-section-number">10.5.1</span> Comparación de modelos RNA</h3>
<p>A continuación vamos a comparar 2 modelos:</p>
<ol style="list-style-type: decimal">
<li>2 capas ocultas de 5 y 3.</li>
<li>1 capa oculta de 8</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Boston.nn.<span class="fl">5.3</span> &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(f
                , <span class="dt">data=</span>train_
                , <span class="dt">hidden=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>)
                , <span class="dt">linear.output=</span><span class="ot">TRUE</span>)

Boston.nn.<span class="dv">8</span> &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(f
                , <span class="dt">data=</span>train_
                , <span class="dt">hidden=</span><span class="dv">8</span>
                , <span class="dt">linear.output=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>Como alternativa a la función <code>plot.nn()</code>, la librería <code>NeuralNetTools</code> incluye funciones gráficas más elegantes. Este elegante gráfico resuelve el problema del desorden visual utilizando el grosor de la línea para representar la magnitud del peso y el color de la línea para representar el signo de peso (negro = positivo, gris = negativo).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(NeuralNetTools)
<span class="kw">plotnet</span>(Boston.nn.<span class="fl">5.3</span>)</code></pre></div>
<p><img src="cursoR_files/figure-html/nntools-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotnet</span>(Boston.nn.<span class="dv">8</span>)</code></pre></div>
<p><img src="cursoR_files/figure-html/nntools-2.png" width="672" style="display: block; margin: auto;" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="análisis-multivariante.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": ["cursoR.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
