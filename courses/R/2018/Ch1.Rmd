---
title: '**Introduction to `R` language**'
author: "Dae-Jin Lee < dlee@bcamath.org >"
date: "BCAM-UPV/EHU Courses 2018-2019"
output:
  slidy_presentation:
    fig_caption: yes
    font_adjustment: 5
    highlight: monochrome
    smart: no
    theme: cerulean
  beamer_presentation:
    colortheme: seahorse
    fonttheme: professionalfonts
  ioslides_presentation:
    highlight: monochrome
---

***********

# Install and load an `R` library
 

Install a package 

```{r,eval=FALSE}
install.packages("DAAG") # (Data Analysis And Graphics)
```

or several packages 

```{r,eval=FALSE}
install.packages(c("lattice","HSAUR2","Hmisc","psych","foreign","xlsx","maps","maptools","RColorBrewer","calibrate"))
```


In `Rstudio` (go to `Packages` and click `Install`)



Once installed the package, load it
```{r,warning=FALSE,message=FALSE}
library(DAAG) # or require(DAAG)
```

## Start with `R`

* Get current working directory 

```{r,eval=FALSE}
getwd() 
```

* list the objects in the current workspace

```{r,eval=FALSE}
ls()
```

* Set working directory

```{r, eval=FALSE}
setwd("/Users/dlee") 
```

* work with your previous commands

```{r,eval=FALSE}
history() # display last 25 commands
history(max.show=Inf) # display all previous commands
```


* save your command history

```{r,eval=FALSE}
savehistory(file="myfile") # default is ".Rhistory"
```

* recall your command history

```{r,eval=FALSE}
loadhistory(file="myfile") # default is ".Rhistory"
```


* save the workspace to the file `.RData` 

```{r, eval=FALSE}
save.image()
```

* save specific objects to a file  if you don't specify the path, the cwd is assumed

```{r,eval=FALSE}
save(<object list>,file="myfile.RData") 
```


* load a workspace into the current session

```{r,eval=FALSE}
load("myfile.RData") 
```


* quit `R`. You will be prompted to save the workspace. 

```{r,eval=FALSE}
q()
```


# Reading data in `R`

The `R` console


```{r}
x <- c(7.82,8.00,7.95) # c means "combine"
x
```

A quicker way is to use `scan()`

```{r,eval=FALSE}
x <- scan()  # enter a number followed by return and blank line to end
1: 7.82
2: 8.00
3: 7.95
4: 
Read 3 items
```
To create a character vector use `""`

```{r}
id <- c("John","Paul","George","Ringo")
```


To read a character vector 
```{r,eval=FALSE}
id <- scan(,"")
1: John
2: Paul
3: George
4: Ringo
5: 
Read 4 items  
```

```{r}
id
```


# Data Import

In most situations, we need to read data from a separate data file. There are several methods for doing this. 

* `scan()` (see `?scan` for help)


```{r}
cat("Example:", "2 3 5 7", "11 13 17", file = "ex.txt", sep = "\n") # creates ex.txt
scan("ex.txt", skip = 1)
scan("ex.txt", skip = 1, nlines = 1) # only 1 line after the skipped one
unlink("ex.data") # tidy up
```

* Several formats are available (`.txt`, `.csv`, `.xls`, `.xlsx`, `SAS`, `Stata`, etc...)

* Some `R` libraries to import data are 

```{r,message=FALSE,warning=FALSE}
library(gdata)
library(foreign)
``` 

\bigskip

* Read data from a `.txt` or `.csv` files

Create a folder, name it `data` and download `cars` data ([cardata.zip](data/cardata.zip))


```{r,eval=FALSE}
mydata1 = read.table("data/cardata.txt") 
mydata2 = read.csv("data/cardata.csv")  
```

* Other formats `.xls` and `.xlsx`

```{r,eval=FALSE,message=FALSE,warning=FALSE}
library(gdata)
mydata3 = read.xls("data/cardata.xls", sheet = 1, header = TRUE)

library(xlsx)
mydata4 = read.xlsx("data/cardata.xlsx", sheetIndex = 1, header = TRUE,colClasses=NA)
```

* Minitab, SPSS, SAS or Stata

```{r, eval=FALSE, message=FALSE}
library(foreign)                   
mydata = read.mtp("mydata.mtp")  # Minitab
mydata = read.spss("myfile", to.data.frame=TRUE) # SPSS
mydata = read.dta("mydata.dta") # Stata
```

* Or
```{r,eval=FALSE}
library(Hmisc)
mydata = spss.get("mydata.por", use.value.labels=TRUE)  # SPSS
```

# Exporting data

* There are numerous methods for exporting `R` objects into other formats. For SPSS, SAS and Stata. you will need to load the `foreign` packages. For Excel, you will need the `xlsx` package.  
 
 - Tab-delimited text file

```{r,eval=FALSE}
mtcars
?mtcars    
write.table(mtcars, "cardata.txt", sep="\t") 
```

*  Excel spreadsheet

```{r,eval=FALSE}
library(xlsx)
write.xlsx(mydata, "mydata.xlsx")
```


# Data vectors

* Download `R code` [here](http://idaejin.github.io/bcam-courses/rbasics/rbasics.R)

* Create a vector of weights and heights

```{r}
weight<-c(60,72,57,90,95,72)  
class(weight)
height<-c(1.75,1.80,1.65,1.90,1.74,1.91)
```

* calculate Body Mass Index
```{r} 
bmi<- weight/height^2
bmi
```

# Basic statistics 

* mean, median, st dev, variance

```{r,eval=FALSE}
mean(weight) 
median(weight)
sd(weight)
var(weight)
```

* summarize data

```{r}
summary(weight)
```

* or

```{r,eval=FALSE}
min(weight)
max(weight)
range(weight)
sum(weight)
length(weight)
```

* Quantiles and percentile

There are several quartiles of an observation variable. The first quartile, or lower quartile, is the value that cuts off the first 25% of the data when it is sorted in ascending order. The second quartile, or median, is the value that cuts off the first 50%. The third quartile, or upper quartile, is the value that cuts off the first 75%. 

```{r}
quantile(weight)
```

The $n^{\rm th}$ percentile of an observation variable is the value that cuts off the first $n$ percent of the data values when it is sorted in ascending order. 

```{r}
quantile(weight,c(0.32,0.57,0.98))
```

* Covariance and correlation 


The *covariance* of two variables $x$ and $y$ in a data sample measures how the two are linearly related. A positive covariance would indicate a positive linear relationship between the variables, and a negative covariance would indicate the opposite.


$$
\rm{Cov}(x,y) = \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})
$$

```{r}
cov(weight,height)
```
The *correlation coefficient* of two variables in a data sample is their covariance divided by the product of their standard deviations. It is a normalised measurement of how the two are linearly related.

Formally, the sample correlation coefficient is defined by the following formula, where $\sigma_x$ and $\sigma_y$ are the sample standard deviations, and $\sigma_xy$ is the covariance. 

$$
      \rho_{xy}  = \frac{\sigma_{xy}}{\sigma_x~\sigma_y}
$$

```{r}
cor(weight,height)
```

# Creating your own functions in `R`

One of the great strengths of `R` is the user's ability to add functions. In fact, many of the functions in `R` are actually functions of functions. The structure of a function is given below.

```{r,eval=FALSE}
myfunction <- function(arg1, arg2, ... ){
  statements
return(object)
}
```

```{r}
f <- function(x){
  x^2
    }
f
```

*Example:*
```{r}
# Given a number
f(2)
# Given a vector
x <- c(1,2,-4,7)
f(x)
```

Let us create a function that returns a set of summary statistics given a numeric vector:

```{r}
mysummary <- function(x){
  mean <- sum(x)/length(x)
   var <- var(x)
    sd <- sd(x)
 range <- range(x)
 result <- list(mean=mean,var=var,sd=sd,range=range)
 return(result)
}
```

Then
```{r}
set.seed(1234)
x <- rnorm(10)
stats <- mysummary(x)
stats
```

# Character vectors and factor variables

```{r}
subject <- c("John","Peter","Chris","Tony","Mary","Jane")
sex <- c("MALE","MALE","MALE","MALE","FEMALE","FEMALE")
class(subject)
table(sex)
```


# Data frames

A `data.frame` is a table or a two-dimensional array-like structure in which each column contains values of one variable and each row contains one set of values from each column. 

```{r}
Dat <- data.frame(subject,sex,weight,height)
# add bmi to Dat
Dat$bmi <- bmi  # or Dat$bmi <- weight/height^2
class(Dat)
str(Dat) # display object structure
```


```{r}
# Change rownames
rownames(Dat)<-c("A","B","C","D","E","F")

# Access to data frame elements (similar to a matrix)
Dat[,1]     # 1st column
Dat[,1:3]   # 1st to 3rd columns
Dat[1:2,]   # 1st to 2nd row
```


# Working with data frames

**Example: Analyze data by groups**

*  Obtain the mean weight, height and BMI means by FEMALES and MALES:

1. Select each group and compute the mean

```{r, results='hide'}
Dat[sex=="MALE",]
Dat[sex=="FEMALE",]

mean(Dat[sex=="MALE",3])  # weight average of MALEs
mean(Dat[sex=="MALE","weight"])
```

2. Use `apply` by columns 
```{r, results='hide'}
apply(Dat[sex=="FEMALE",3:5],2,mean)
apply(Dat[sex=="MALE",3:5],2,mean)

# we can use apply with our own function
apply(Dat[sex=="FEMALE",3:5],2,function(x){x+2})
```

3. `by` and `colMeans`

```{r, results='hide'}
# 'by' splits your data by factors and do calculations on each subset.
by(Dat[,3:5],sex, colMeans) 
```

4. `aggregate`

```{r, results='hide'}
# another option
aggregate(Dat[,3:5], by=list(sex),mean) 
```

------------------------------------

# Logical vectors

* Choose individuals with `BMI>22`
```{r,results='hide'}
bmi
bmi>22
as.numeric(bmi>22) # convert a logical condition to a numeric value 0/1
which(bmi>22)  # gives the position of bmi for which bmi>22
```

* Which are between $20$ and $25$?

```{r,results='hide'}
bmi > 20 & bmi < 25
which(bmi > 20 & bmi < 25)
```

--------------------------------------

# Working with vectors 

* Concatenate

```{r,results='hide'}
x <- c(2, 3, 5, 2, 7, 1)
y <- c(10, 15, 12)
z <- c(x,y)  # concatenates x and y
```

* list two vectors

```{r}
zz <- list(x,y) # create a list
unlist(zz) # unlist the list converting it to a concatenated vector
``` 

* subset of vectors

```{r}
x[c(1,3,4)]

x[-c(2,6)] # negative subscripts omit the chosen elements 
```

* Sequences
```{r}
seq(1,9) # or 1:9
seq(1,9,by=1)
seq(1,9,by=0.5)
seq(1,9,length=20)
```

* Replicates

```{r,results='hide'}
oops <- c(7,9,13)
rep(oops,3) # repeats the entire vector "oops" three times
rep(oops,1:3) # this function has the number 3 replaced 
              #  by a vector with the three values (1,2,3) 
              #  indicating that 7 should be repeated once, 9 twice and 13 three times.

rep(c(2,3,5), 4)
rep(1:2,c(10,15))

rep(c("MALE","FEMALE"),c(4,2)) # it also works with character vectors 
c(rep("MALE",3), rep("FEMALE",2))
```

---------------------------------------------


# Matrices and arrays

```{r}
x<- 1:12
x
dim(x)<-c(3,4)  # 3 rows and 4 columns

X <- matrix(1:12,nrow=3,byrow=TRUE)
X

X <- matrix(1:12,nrow=3,byrow=FALSE)
X

# rownames, colnames

rownames(X) <- c("A","B","C")
X
colnames(X) <- LETTERS[4:7]
X
colnames(X) <- month.abb[4:7]
X
```

* Column/Row bind operations `cbind()`, `rbind()`

```{r}
Y <- matrix(0.1*(1:12),3,4)

cbind(X,Y)  # bind column-wise
rbind(X,Y)  # bind row-wise
```

-----------------------------------------------

# Factors

`Factors are the data objects which are used to categorize the data and store it as levels.


```{r}
gender<-c(rep("female",691),rep("male",692))
is.factor(gender)

class(gender)

# change vector to factor (i.e. a category)
gender<- factor(gender)
is.factor(gender)
levels(gender)

summary(gender)
table(gender)

status<- c(0,3,2,1,4,5)    # This command creates a numerical vector pain, 
                           #    encoding the pain level of five patients.
fstatus <- factor(status, levels=0:5)
levels(fstatus) <- c("student","engineer","unemployed","lawyer","economist","dentist")

Dat$status <- fstatus
Dat
```

 * Changing the order of Levels:
 
```{r}
data <- c("East","West","East","North","North","East","West",
   "West","West","East","North")
# Create the factors
factor_data <- factor(data)
print(factor_data)

# Apply the factor function with required order of the level.
new_order_data <- factor(factor_data,levels = c("East","West","North"))
print(new_order_data)
```

#  Indexing vector with logicals

```{r}
a <- c(1,2,3,4,5)
b <- c(TRUE,FALSE,FALSE,TRUE,FALSE)

max(a[b])

sum(a[b])
````

# Missing values

In `R`, missing values are represented by the symbol `NA` (not available) . Impossible values (e.g., dividing by zero) are represented by the symbol `NaN` (not a number). 

```{r}
a <- c(1,2,3,4,NA)
sum(a)
```

Excluding missing values from functions

```{r}
sum(a,na.rm=TRUE)

a <- c(1,2,3,4,NA)
is.na(a)
```

The function `complete.cases()` returns a logical vector indicating which cases are complete.

```{r}
complete.cases(a)
```

The function `na.omit()` returns the object with listwise deletion of missing values. 

```{r}
na.omit(a) 
```

`NA` in data frames:

```{r, fig.width=10, fig.height=6,eval=TRUE, fig.align="center"}
require(graphics)
?airquality
str(airquality)
pairs(airquality, panel = panel.smooth, main = "airquality data")
ok <- complete.cases(airquality)
airquality[ok,]
```


# Working with data frames

 * A data frame is used for storing data tables. It is a list of vectors of equal length. 
```{r,results="hide"}
mtcars
?mtcars       # or help(mtcars)
```

* look at the first rows

```{r}
head(mtcars)
```

* Structure of the data frame

```{r}
str(mtcars) # display the structure of the data frame
```

* Select a car model:
```{r, eval=FALSE}
mtcars["Mazda RX4",] # using rows and columns names
mtcars[c("Datsun 710", "Camaro Z28"),] 
```

* Or specific variables

```{r, eval=FALSE}
mtcars[,c("mpg","am")]
```

There are some packages that include particular functions to summarize data frames, for instance the library `psych` has the function `describe`

```{r, message=FALSE, warning=FALSE, eval=FALSE}
library(psych)
describe(mtcars)
```


# Basic plotting and data analysis in `R`

*  Scatterplot

```{r,fig.align='center'}
data("mtcars")
attach(mtcars) #?attach
plot(wt, mpg, main="Scatterplot Example",
   xlab="Car Weight", ylab="Miles Per Gallon", pch=19) 
```

* Basic Scatterplot Matrix

```{r,fig.align='center'}
pairs(~mpg+disp+drat+wt,data=mtcars,
   main="Simple Scatterplot Matrix")
```

* Barplot

```{r,fig.pos='center',fig.align='center'}
tab <- table(mtcars[,c("cyl")])
barplot(tab)
```

* Piechart

```{r,fig.align='center'}
pie(tab)
```


**Exercises:**

1. The data.frame `VADeaths` contains the death rates per 1000 in Virginia (US) in 1940. The death rates are measured per 1000 population per year. They are cross-classified by age group (rows) and population group (columns). 

```{r}
data(VADeaths)
VADeaths
```

* Compute the mean for each age group. 

      + **Result:**

```{r,echo=FALSE}
apply(VADeaths,1,mean)
```

* Compute the mean for each population group. 

      + **Result:** 
      
```{r,echo=FALSE}
apply(VADeaths,2,mean)
```

2. The  `data.frame` `rainforest` contains several variables from different `species`

```{r, results='hide'}
library(DAAG)
rainforest
?rainforest
names(rainforest)
```

  * Create a table of counts for each `species` and make a graphic with the results. 
  
      + **Result:**
      
```{r,echo=FALSE}
table(rainforest$species)
barplot(table(rainforest$species))
```

3. The `Acmena` `data.frame` is created from  `rainforest` using the function `subset`. 

  * Plot the relationship between the wood biomass (`wood`) and the diameter of the breast height (`dbh`). Use also a logarithm scale.

```{r}
Acmena <- subset(rainforest, species == "Acmena smithii")
```

 
```{r,echo=FALSE, fig.width=10,fig.height=8, fig.align='center'}
par(mfrow=c(1,2))
plot(wood~dbh,data=Acmena,pch=19, main="plot of dbh vs wood")
plot(log(wood)~log(dbh),data=Acmena,pch=19,main="log transformation")
```


  * Compute a histogram of variable `dbh` using function `hist`

```{r,echo=FALSE,fig.align='center'}
hist(Acmena$dbh,col="grey")
```

4. Create a vector of the positive odd integers less than 100 and remove the values greater than 60 and less than 80.

    * **Result:** 
    
```{r,echo=FALSE}
  x <- seq(1,100,by=2)
  x[x>60 & x<80]
```


* [Solutions here](http://idaejin.github.io/bcam-courses/rbasics/rbasics_sol.R)



# Operators

`R`'s binary and logical operators will look very familiar to programmers. Note that binary operators work on vectors and matrices as well as scalars. 


## Arithmetic Operators 

  Operator      | Description
--------------- | -------------
      `+`       | addition
      `-`       | subtraction
      `*` 	    | multiplication
      `/` 	    | division
  `^` or `**` 	| exponentiation
    x `%%` y 	  | modulus (x mod y) 5%%2 is 1
    x `%/%` y 	| integer division 5%/%2 is 2 

## Logical Operators

  Operator      | Description
--------------- | -------------
      `<`       | less than
      `>`       | greater than
      `<=` 	    | less or equal to
      `>=` 	    | greater or equal to
      `==`      | exactly equal to
      `!=` 	    | not equal to 
      `!x` 	    | Not x
     `x|y`      | `x` OR `y`
     `x&y` 	    | `x` AND `y` 
  `isTRUE(x)` 	|  test if `x` is `TRUE`
      
      
      
```{r}
# An example
x <- c(1:10)
x[(x>8) | (x<5)]
# yields 1 2 3 4 9 10

# How it works
x <- c(1:10)
x
x > 8
x < 5
x > 8 | x < 5
x[c(T,T,T,T,F,F,F,F,T,T)]
```

## Control Structures

These allow you to control the flow of execution of a script typically inside of a function. Common ones include:

  
  +    if, else
  
  +    for
  
  +    while
  
  +    repeat
  
  +    break
  
  +    next
  
  +    return


## Conditional Executions

**`if`**

```{r,eval=FALSE}
if (condition) {
    # do something
} else {
    # do something else
}
```

e.g.:

```{r}
x <- 1:15
if (sample(x, 1) <= 10) { # ?sample  
    print("x is less than 10")
} else {
    print("x is greater than 10")
}
```

**Vectorization with `ifelse`**

```{r,eval=FALSE}
ifelse(x <= 10, "x less than 10", "x greater than 10")
```

Other valid ways of writing if/else


```{r,eval=FALSE}
if (sample(x, 1) < 10) {
    y <- 5
} else {
    y <- 0
}
```

```{r,eval=FALSE}
y <- if (sample(x, 1) < 10) {
    5
} else {
    0
}
```

**for**

A `for` loop works on an iterable variable and assigns successive values till the end of a sequence.

```{r}
for (i in 1:10) {
    print(i)
}
```

```{r}
x <- c("apples", "oranges", "bananas", "strawberries")

for (i in x) {
    print(x[i])
}

for (i in 1:4) {
    print(x[i])
}

for (i in seq(x)) {
    print(x[i])
}

for (i in 1:4) print(x[i])
```


**nested lopps**

```{r}
m <- matrix(1:10, 2)
for (i in seq(nrow(m))) {
    for (j in seq(ncol(m))) {
        print(m[i, j])
    }
}
```

**while**

```{r}
i <- 1
while (i < 10) {
    print(i)
    i <- i + 1
}
```
Be sure there is a way to exit out of a `while` loop.

**Repeat and break**
```{r,eval=FALSE}
repeat {
    # simulations; generate some value have an expectation if within some range,
    # then exit the loop
    if ((value - expectation) <= threshold) {
        break
    }
}
```

**Next**
```{r}
for (i in 1:20) {
    if (i%%2 == 1) {  # %% is the modulus
        next
    } else {
        print(i)
    }
}
```

## Comparison Operators

  - equal: `==`
  
```{r}
  "hola" == "hola"
  "hola" == "Hola"
   1 == 2-1
```

  
  
  - not equal: `!=`
  

```{r}
    a <- c(1,2,4,5)
    b <- c(1,2,3,5) 
    a == b
    a != b
```
  
  - greater/less than: `>` `<`

```{r}
set.seed(1)
a <- rnorm(10)
b <- rnorm(10)
a<b
```  

  - greater/less than or equal: `>=` `<=`
  
```{r}
set.seed(2)
a <- rnorm(10)
b <- rnorm(10)
a >= b
```


  - `which`
  
```{r}
set.seed(3)
which(a>b)

LETTERS
which(LETTERS=="R")
```
 
  - `which.min` or `which.max`
```{r}
set.seed(4)
a <- rnorm(10)
a
which.min(a)
which.max(a)
```

  - `is.na`
```{r}
 a[2] <- NA
is.na(a)
which(is.na(a))
```

## Logical Operators

  - and: `&`

```{r}
z = 1:6
which(2 < z & z > 3)
```

  - or: `|`
  
```{r}
z = 1:6
(z > 2) & (z < 5)
which((z > 2) & (z < 5))
```

  - not: `!`

```{r}
x <- c(TRUE,FALSE,0,6)
y <- c(FALSE,TRUE,FALSE,TRUE)

!x
```

Operators `&` and `|` perform element-wise operation producing the result having the length of the longer operand. But `&&` and `||` examines only the first element of the operands resulting into a single length logical vector. Zero is considered `FALSE` and non-zero numbers are taken as `TRUE`.

 **Example:**
  - `&&` vs `&`

```{r}
x&y
x&&y
```

 - `||` vs `|`
 
 
```{r}
x||y
x|y
```


## `if` statements

`if(cond1=true) { cmd1 } else { cmd2 }`

```{r}
if(1==0) {
    print(1)
} else {
    print(2)
}
```

## `ifelse` statement

`ifelse(test, true_value, false_value)`

```{r}
x <- 1:10 # Creates sample data
ifelse(x<5 | x>8, x, 0)
```


# Loops

The most commonly used loop structures in `R` are `for`, `while` and `apply` loops. Less common are `repeat` loops. The `break` function is used to break out of loops, and next halts the processing of the current iteration and advances the looping index.


## Writing a simple for loop in `R`

Suppose you want to do several printouts of the following form: The year is [year] where [year] is equal to 2010, 2011, up to 2015. You can do this as follows:


```{r}
print(paste("The year is", 2010))
```



## `for`

For loops are controlled by a looping vector. In every iteration of the loop one value in the looping vector is assigned to a variable that can be used in the statements of the body of the loop. Usually, the number of loop iterations is defined by the number of values stored in the looping vector and they are processed in the same order as they are stored in the looping vector.


Syntax
```
for(variable in sequence) {
    statements
}
```


```{r}
for (j in 1:5)
{
  print(j^2)
}
```

Repeat the loop saving the resuls in a vector `x`. 

```{r}
n = 5
x = NULL  # creates a NULL object
for (j in 1:n)
{
  x[j] = j^2
}
x
```

Let's use a for loop to estimate the average of squaring the result of a roll of a dice.

```{r}
nsides = 6
ntrials = 1000
trials = NULL
for (j in 1:ntrials)
{
  trials[j] = sample(1:nsides,1)  # We get one sample at a time
}
mean(trials^2)
```

**Example:** stop on condition and print error message

```{r,eval=FALSE}
x <- 1:10
z <- NULL
for(i in seq(along=x)) {
    if (x[i]<5) {
        z <- c(z,x[i]-1) 
    } else {
        stop("values need to be <5")
    }
}
## Error: values need to be <5
z
## [1] 0 1 2 3
```



## `while`

Similar to `for` loop, but the iterations are controlled by a conditional statement.

```{r}
z <- 0
while(z < 5) {
    z <- z + 2
    print(z) 
}
```

## `apply` loop family

&nsbp;

For Two-Dimensional Data Sets: apply

**Syntax:**

```
apply(X, MARGIN, FUN, ARGs)
```

`X`: `array`, `matrix` or `data.frame`; `MARGIN`: 1 for rows, 2 for columns, `c(1,2)` for both; `FUN`: one or more functions; `ARGs`: possible arguments for function.

```{r, eval=FALSE}
## Example for applying predefined mean function
apply(mtcars[,1:3], 1, mean)

## With custom function
x <- 1:10
test <- function(x) { # Defines some custom function
    if(x < 5) {
        x-1
    } else {
        x / x
    }
} 

apply(as.matrix(x), 1, test) 

## Same as above but with a single line of code
apply(as.matrix(x), 1, function(x) { if (x<5) { x-1 } else { x/x } })
```

**For Ragged Arrays: `tapply`**

Apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors.

```{r,eval=TRUE}
## Computes mean values of vector agregates defined by factor
tapply(as.vector(mtcars$mpg), factor(mtcars$cyl), mean)

## The aggregate function provides related utilities
aggregate(mtcars[,c(1,3,4)], list(mtcars$cyl), mean)
```


**For Vectors and Lists: `lapply` and `sapply`**

Both apply a function to vector or list objects. The function `lapply` returns a list, while `sapply` attempts to return the simplest data object, such as `vector` or `matrix` instead of `list`. 

*Syntax*

```
lapply(X,FUN)
sapply(X,FUN)
```

```{r, echo=TRUE}
## Creates a sample list
mylist <- as.list(mtcars[,c(1,4,6)])
mylist
```

Compute sum of each list component and return result as list

```{r}
lapply(mylist, sum)
```

Compute sum of each list component and return result as vector

```{r}
sapply(mylist, sum)
```

## Other Loops

**Repeat Loop**

*Syntax*

`repeat` statements

Loop is repeated until a break is specified. This means there needs to be a second statement to test whether or not to break from the loop.

*Example:*
```
z <- 0
repeat {
    z <- z + 1
    print(z)
    if(z > 100) break()
}
```

## Improving Speed Performance of Loops

Looping over very large data sets can become slow in `R`. However, this limitation can be overcome by eliminating certain operations in loops or avoiding loops over the data intensive dimension in an object altogether. The latter can be achieved by performing mainly vector-to-vector or matrix-to-matrix computations which run often over 100 times faster than the corresponding `for()` or `apply()` loops in `R`. For this purpose, one can make use of the existing speed-optimized R functions (e.g.: `rowSums`, `rowMeans`, `table`, `tabulate`) or one can design custom functions that avoid expensive `R` loops by using vector- or matrix-based approaches. Alternatively, one can write programs that will perform all time consuming computations on the C-level.


1. Speed comparison of `for` loops with an append versus and inject step

```{r,eval=FALSE}
N <- 1e3
myMA <- matrix(rnorm(N), N, 10, dimnames=list(1:N, paste("C", 1:10, sep="")))
results <- NULL
system.time(for(i in seq(along=myMA[,1])) 
            results <- c(results, mean(myMA[i,])))

results <- numeric(length(myMA[,1]))
system.time(for(i in seq(along=myMA[,1])) 
            results[i] <- mean(myMA[i,]))
```
The inject approach is 20-50 times faster than the append version.

2. Speed comparison of `apply` loop versus `rowMeans` for computing the mean for each row in a large matrix:

```{r,eval=FALSE}
system.time(myMAmean <- apply(myMA, 1, mean))
system.time(myMAmean <- rowMeans(myMA))
```

The `rowMeans` approach is over 200 times faster than the `apply` loop.



***********

# Scatterplots

```{r, message= FALSE, warning=FALSE}
library(MASS)
data("mammals")
?mammals
head(mammals)
attach(mammals)
species <- row.names(mammals)
x <- body
y <- brain
```

```{r,fig.align='center'}
library(calibrate)
# scatterplot
plot(x,y, xlab = "body weight in kgr", ylab = "brain weight in gr", 
     main="Body vs Brain weight \n for 62 Species of Land Mammals",xlim=c(0,8500))
textxy(x,y,labs=species,col = "blue",cex=0.85) 
```

Identify a point in the scatterplot
```{r, eval=FALSE}
identify(x,y,species)
```

Plot in the log scale
```{r,fig.align='center'}
plot(log(x),log(y), xlab = "log body weight in kgr", ylab = "log brain weight in gr", 
     main="log Body vs log Brain weight \n for 62 Species of Land Mammals")
textxy(log(x),log(y),labs=species,col = "blue",cex=0.85) 
```

Identify a point in the log scale scatterplot
```{r, eval=FALSE}
identify(log(x),log(y),species)
```


**Multiple Data Sets on One Plot**

One common task is to plot multiple data sets on the same plot. In many situations, the way to do this is to create the initial plot and then add additional information to the plot. For example, to plot bivariate data the `plot` command is used to initialise and create the plot. The `points` command can then be used to add additional datasets to the plot.


```{r,fig.align='center'}
set.seed(1234)
 x <- rnorm(10,sd=5,mean=20)
 y <- 2.5*x - 1.0 + rnorm(10,sd=9,mean=0)
 cor(x,y)
 plot(x,y,xlab="Independent",ylab="Dependent",main="Random plot")
 x1 <- runif(8,15,25)
 y1 <- 2.5*x1 - 1.0 + runif(8,-6,6)
 points(x1,y1,col=2)
```

with legend and $(x_2,y_2)$ points:
```{r}
set.seed(1234)
x2 <- runif(8,15,25)
y2 <- 2.5*x2 - 1.0 + runif(8,-6,6)
 plot(x,y,xlab="Independent",ylab="Dependent",main="Random plot")
 points(x1,y1,col=2,pch=3)
 points(x2,y2,col=4,pch=5)
 legend("topleft",c("Original","one","two"),col=c(1,2,4),pch=c(1,3,5))
```

<!-- **Errors bars:** -->

<!-- ```{r,fig.width=8,fig.height=6} -->
<!-- plot(x,y,xlab="Independent",ylab="Dependent",main="Random plot",ylim=c(20,90)) -->
<!-- xHigh <- x -->
<!-- yHigh <- y + abs(rnorm(10,sd=3.5)) -->
<!-- xLow <- x -->
<!-- yLow <- y - abs(rnorm(10,sd=3.1)) -->
<!-- arrows(xHigh,yHigh,xLow,yLow,col=2,angle=90,length=0.1,code=3) -->
<!-- ``` -->

<!-- ```{r,fig.width=8,fig.height=6} -->
<!-- plot(1:20,0*(1:20),pch=1:20,cex=2) -->
<!-- ``` -->

**Multiple Graphs on One Image:**

```{r,fig.align='center'}
set.seed(1234)
 par(mfrow=c(2,3))
 boxplot(rnorm(100),main="first plot")
 boxplot(rgamma(100,2),main="second plot", horizontal=TRUE,col="bisque")
 plot(rnorm(100),xlab="third plot",
      ylab="y-label",main="x-label")
 hist(rnorm(100),main="fourth plot",col="lightgrey")
 hist(rexp(100),main="fifth plot",col="blue")
 plot(rnorm(100),rexp(100),main="sixth plot")
```

**Pairwise relationships**

```{r}
uData <- rnorm(20)
vData <- rnorm(20,mean=5)
wData <- uData + 2*vData + rnorm(20,sd=0.5)
xData <- -2*uData+rnorm(20,sd=0.1)
yData <-  3*vData+rnorm(20,sd=2.5)
d <- data.frame(u=uData,v=vData,w=wData,x=xData,y=yData)
pairs(d)
```

**Plotting correlations**

The function `corrplot` in the `library(corrplot)` visualizes a correlation matrix calculate with function `cor`

```{r, fig.width=8,fig.align='center'}
library(corrplot)
M <- cor(d)
corrplot(M, method="circle",type="upper")
```

**Plotting surfaces: `image`, `contour` and `persp` plots**

```{r, fig.width=10, fig.height=10,fig.align='center'}
x <- seq(0,2*pi,by=pi/50)
y <- x
xg <- (x*0+1) %*% t(y)
yg <- (x) %*% t(y*0+1)
f <- sin(xg*yg)

par(mfrow=c(2,2))
image(x,y,f)
contour(x,y,f)
contour(x,y,f,nlevels=4)
image(x,y,f,col=grey.colors(100))
contour(x,y,f,nlevels=4,add=TRUE,col="red")
```


Similarly, one can use `persp` plot
```{r,fig.align='center'}
persp(x,y,f,theta=-30,phi=55,col="lightgrey",shade=.01)
```


Or plot images

```{r,message=FALSE,warning=FALSE,fig.width=10,fig.height=10,fig.align='center'}
library(fields)
data(lennon)
image(lennon,col=grey(seq(0,1,l=256)))
```

# Tables and Cross-classification

```{r}
library(MASS)
data(quine)
?quine
attach(quine)
table(Sex)
table(Sex,Age)

# or xtabs
xtabs(~Sex+Age,data=quine)
xtabs(~Sex+Age+Eth,data=quine)
```

**Calculations of cross-classifications**

```{r}
tapply(Days,Age,mean)
```

```{r}
tapply(Days,list(Sex,Age),mean)
```


```{r}
tapply(Days,list(Sex,Age),function(x) sqrt(var(x)/length(x)))
```


# Qualitative data

A data sample is called qualitative, also known as categorical if its values belong to a collection of known defined non-overlapping classes. 

Let us consider some artificial data consisting of the `treatment` and `improvement` of patients with rheumatoid arthritis.

```{r}
treatment <- factor(rep(c(1, 2), c(43, 41)), levels = c(1, 2),
                    labels = c("placebo", "treated"))
improved <- factor(rep(c(1, 2, 3, 1, 2, 3), c(29, 7, 7, 13, 7, 21)),
                   levels = c(1, 2, 3),
                   labels = c("none", "some", "marked"))
```
We can compute a cross-classification table
```{r}
xtabs(~treatment+improved)
```

Graphically,
```{r,fig.align='center'}
spineplot(improved ~ treatment)
```


The `R` dataset `UCBAdmissions` contains aggregated data on applicants to graduate school at Berkeley for the six largest departments in 1973 classified by admission and sex.


```{r}
data("UCBAdmissions")
?UCBAdmissions
apply(UCBAdmissions, c(2,1), sum)
prop.table(apply(UCBAdmissions, c(2,1), sum))
ftable(UCBAdmissions)
```

The same but with a more readable format can be obtained using `ftable`
```{r}
ftable(round(prop.table(UCBAdmissions), 3),
       row.vars="Dept", col.vars = c("Gender", "Admit"))
```

More interesting are the proportions admitted for each `Gender` by `Dept` combination (dimensions 2 and 3 of the array).  Notice that `male` and `female` admission rates are about the same in all departments, except "A", where female admission rates are higher.

```{r}
# prop.table(UCBAdmissions, c(2,3))
ftable(round(prop.table(UCBAdmissions, c(2,3)), 2),
       row.vars="Dept", col.vars = c("Gender", "Admit"))
```


```{r}
## Data aggregated over departments
apply(UCBAdmissions, c(1, 2), sum)
```


Applications and admissions by department at UC Berkeley can be viewed graphically.

```{r,fig.align='center'}
spineplot(margin.table(UCBAdmissions, c(3, 2)),
           main = "Applications at UCB")
spineplot(margin.table(UCBAdmissions, c(3, 1)),
           main = "Admissions at UCB")

```


This data set is frequently used for illustrating *Simpson's paradox*. At issue is whether the data show evidence of sex bias in admission practices. There were 2691 male applicants, of whom 1198 (44.5%) were admitted, compared with 1835 female applicants of whom 557 (30.4%) were admitted. Men were much more successful in admissions than women. [Wikipedia: Gender Bias UC Berkeley](https://en.wikipedia.org/wiki/Simpson%27s_paradox#UC_Berkeley_gender_bias). See animation at [link](http://vudlab.com/simpsons/) 
 

# Quantitative data

Quantitative data, also known as continuous data, consists of numeric data that support arithmetic operations. 

```{r}
head(faithful)
```

It consists of a collection of observations of the Old Faithful geyser in the USA Yellowstone National Park. 
&nbsp;

There are two observation variables in the dataset. The first one, called `eruptions`, is the duration of the geyser eruptions. The second one, called `waiting`, is the length of waiting period until the next eruption. It turns out there is a correlation between the two variables.

```{r,fig.align='center'}
plot(faithful)
```

# Frequency distribution of quantitative data

The frequency distribution of a data variable is a summary of the data occurrence in a collection of non-overlapping categories. 

Let us find the frequency distribution of the eruption duration in `faithful` data set.

```{r}
duration <- faithful$eruptions
range(duration)
```

&nbsp;

Now we create the range of non-overlapping sub-intervals by defining a sequence of equal distance break points. 

If we round the endpoints of the interval [1.6, 5.1] to the closest half-integers, we come up with the interval [1.5, 5.5]. Hence we set the breakpoints to be the half-integer sequence { 1.5, 2.0, 2.5, ... }. 

```{r}
breaks <- seq(1.5,5.5,by=0.5)
breaks
```

&nbsp;

Classify the eruption durations according to the half-unit-length sub-intervals with `cut`. As the intervals are to be closed on the left, and open on the right, we set the right argument to `FALSE`. 

```{r}
duration.cut = cut(duration, breaks, right=FALSE) 
```
Compute the frequency of eruptions in each sub-interval with the table function. 

```{r}
duration.freq = table(duration.cut) 
duration.freq
```

`hist` function does all the computaions to find the frequency distribution:

```{r}
freq <- hist(duration)
freq

freq <- hist(duration,breaks = breaks)

hist(duration,50)
```


**Density estimation** builds an estimate of some underlying probability density function
using an observed data sample.

```{r,fig.align='center'}
library(graphics)
d <- density(faithful$eruptions)
d
plot(d)
```

&nbsp;
Two dimension histogram:

```{r,message=FALSE,warning=FALSE,fig.align='center'}
library(gplots)
h2 <- hist2d(faithful, nbins=30,xlab="Duration in minutes",ylab="Waiting")
h2
names(h2)
```

&nbsp;

Relative frequencies 

```{r}
duration.relfreq <- duration.freq / nrow(faithful) 
tab <- cbind(duration.freq, duration.relfreq) 
apply(tab,2,sum)
```

&nbsp;

Cumulative frequency distribution

```{r}
cumsum(duration.freq)
cumsum(duration.relfreq)
```

<!-- We can plot the cumulative relative frequency graph of a quantitative variable, which is a curve graphically showing the cumulative relative frequency distribution.  -->
<!-- The e.c.d.f. (empirical cumulative distribution function) $F_n$ is a step function with jumps $i/n$ at observation values, where $i$ is the number of tied observations at that value. Missing values are ignored. -->

<!-- For observations $x = (x_1,x_2, ... x_n)$, $F_n$ is the fraction of observations less or equal to $t$, i.e., -->

<!-- $$ -->
<!-- F_n(t) = \#{x_i <= t}/n = 1/n \sum_{i=1}^n I(x_i \leq t). -->
<!-- $$ -->
<!-- where $I$ is an indication function. -->




<!-- ```{r} -->
<!-- plot(ecdf(duration)) -->
<!-- ``` -->

**Bivariante Density estimation:**
```{r, fig.align='center'}
data("faithful")
attach(faithful)
Dens2d<-kde2d(eruptions,waiting)
image(Dens2d,xlab="eruptions",ylab="waiting")
contour(Dens2d,add=TRUE,col="black",lwd=2,nlevels=5)
detach("faithful")
```

**Perspective plot:**

```{r,fig.align='center'}
persp(Dens2d,phi=30,theta=20,d=5,xlab="eruptions",ylab="waiting",zlab="",shade=.2,col="lightblue",expand=.85,ticktype = "detailed")
```

# Advanced plotting `ggplot2`

```{r,eval=FALSE}
library(ggplot2)
```

**Why `ggplot2`?**


Advantages of ggplot2

   - consistent underlying `grammar of graphics' (Wilkinson, 2005)

   - plot specification at a high level of abstraction

   - very flexible

   - theme system for polishing plot appearance

   - mature and complete graphics system

   - many users, active mailing list


*Example:* `Housing data` [download](http://idaejin.github.io/bcam-courses/R/2017/data/dataSets.zip)

```{r}
housing <- read.csv("data/landdata-states.csv")
head(housing[1:5])

# change column names
names(housing)[names(housing) == "Land.Share..Pct."] <- "Land.Share.Pct"
head(housing, 10)
```


## `ggplot2` VS Base for simple graphs

Base graphics histogram are:

```{r,fig.align='center'}
hist(housing$Home.Value)
```

```{r,message=FALSE,warning=FALSE,fig.align='center'}
library(ggplot2)
ggplot(housing, aes(x = Home.Value)) +
  geom_histogram()
```

Another simple graph

```{r,fig.align='center'}
plot(Home.Value ~ Date,
     data=subset(housing, State == "MA"))
points(Home.Value ~ Date, col="red",
       data=subset(housing, State == "TX"))
legend(1975, 400000,
       c("MA", "TX"), title="State",
       col=c("black", "red"),
       pch=c(1, 1))
```

`ggplot` version, colored scatter plot example:

```{r,fig.align='center'}
ggplot(subset(housing, State %in% c("MA", "TX")),
       aes(x=Date,
           y=Home.Value,
           color=State))+
  geom_point()
```


**Geometric Objects And Aesthetics**

    *Aesthetic Mapping:*

 In `ggplot` land /aesthetic/ means "something you can see". Examples include:
    
  - position (i.e., on the x and y axes)
    
  - color ("outside" color)

  - fill ("inside" color)
  
  - shape (of points)

  - linetype
     
  - size

Each type of geom accepts only a subset of all aesthetics--refer to the geom help pages to see what mappings each geom accepts. Aesthetic
mappings are set with the `aes()` function.

### Geometric Objects (`geom`)

Geometric objects are the actual marks we put on a plot. 

Examples include:

  - points (`geom_point`, for scatter plots, dot plots, etc)
  
  - lines (`geom_line`, for time series, trend lines, etc)
  
  - boxplot (`geom_boxplot`, for, boxplots)

  - A plot must have at least one geom; there is no upper limit. You can add a `geom` to a plot using the `+` operator



**More** at [http://had.co.nz/ggplot2/](http://had.co.nz/ggplot2/)


**Some examples:**

```{r,message=FALSE,warning=FALSE,fig.align='center'}
library(ggplot2)
?qplot
qplot(displ, hwy, data = mpg, colour = factor(cyl))
qplot(mpg, wt, data = mtcars)
qplot(mpg, wt, data = mtcars, colour = cyl)
qplot(mpg, wt, data = mtcars, size = cyl)
qplot(mpg, wt, data = mtcars, size = cyl, alpha = I(0.7))
qplot(mpg, wt, data = mtcars, facets = vs ~ am)

qplot(displ, hwy, data=mpg, facets = . ~ year) + geom_smooth()

p <- ggplot(mtcars)
p <- p + aes(wt, hp)
p + geom_point(aes(colour = factor(cyl)))

p <- ggplot(mtcars, aes(mpg, wt))
p + geom_point(colour = "darkblue")
```

Get data from the internet

```{r, eval = FALSE}
filepath <- "http://idaejin.github.io/courses/R/2018/data/ggplot2_data.txt"

myData<-read.table(file=url(filepath),header=TRUE,sep="\t")

str(myData)

qplot(data=myData,x=BM,main="Histogram of BodyMass")

qplot(data=myData,x=BM,y=var1,log="xy",color=Tribe)
```


# Maps



## Example: Malignant Melanoma in the USA

Fisher and Belle (1993) report mortality rates due to malignant melanoma of the skin for white males during the period 1950-1969, for each state on the US mainland. 


```{r}
data("USmelanoma",package="HSAUR2")
head(USmelanoma)
```

A data consists of 48 observations on the following 5 variables.

  * `mortality`: number of white males died due to malignant melanoma 1950-1969 per one million inhabitants.

  * `latitude`: latitude of the geographic centre of the state.

  * `longitude`: longitude of the geographic centre of each state.

  * `ocean`: a binary variable indicating contiguity to an ocean at levels `no` or `yes`.


## Plotting mortality rates

```{r}
xr <- range(USmelanoma$mortality) * c(0.9, 1.1)
```

Let us plot mortality rates in 

```{r,fig.align='center'}
#layout(matrix(1:2, nrow = 2))
boxplot(USmelanoma$mortality, ylim = xr, horizontal = TRUE,xlab = "Mortality")
hist(USmelanoma$mortality, xlim = xr, xlab = "", main = "",axes = FALSE, ylab = "")
axis(1)
```

Malignant melanoma mortality rates by contiguity to an ocean

```{r,fig.align='center'}
plot(mortality ~ ocean, data = USmelanoma, 
     xlab = "Contiguity to an ocean", ylab = "Mortality")
```

Histograms can often be misleading for displaying distributions because of their dependence on the number of classes chosen. An alternative is to formally estimate the density function of a variable and then plot the resulting estimate.

The estimated densities of malignant melanoma mortality rates by contiguity to an ocean looks like this:

```{r,fig.width=12,fig.height=10,fig.align='center'}
dyes<- with(USmelanoma, density(mortality[ocean == "yes"]))
dno <- with(USmelanoma, density(mortality[ocean == "no"]))
plot(dyes, lty = 1, xlim = xr, main = "", ylim = c(0, 0.018))
lines(dno, lty = 2)
legend("topright", lty = 1:2, legend = c("Coastal State","Land State"), bty = "n")
```


Now we might move on to look at how mortality rates are related to the geographic location of a state as represented by the latitude and longitude of the centre of the state. 

```{r,fig.align='center'}
layout(matrix(1:2, ncol = 2))
plot(mortality ~ -longitude, data = USmelanoma)
plot(mortality ~ latitude, data = USmelanoma)
```

## Mapping mortality rates

The data contains the longitude and latitude of the centroids 

```{r,fig.align='center',message=FALSE,warning=FALSE}
plot(-USmelanoma$longitude,USmelanoma$latitude,
     asp=1.5,cex=.3,pch=19,col="blue")
```


```{r,fig.align='center',message=FALSE,warning=FALSE}
library("sp")
library("maps")
library("maptools")
library("RColorBrewer")
map("state")
points(-USmelanoma$longitude,USmelanoma$latitude,asp=1.5,cex=.3,pch=19,col="blue")
```

```{r,fig.align='center',message=FALSE,warning=FALSE}
#qplot(-USmelanoma$longitude,USmelanoma$latitude,colour=USmelanoma$mortality,asp=1.5)+scale_color_gradient(low="blue", high="red")+geom_point()

#Create a function to generate a continuous color palette
rbPal <- colorRampPalette(c('blue','grey','red'))
#This adds a column of color values
# based on the y values
USmelanoma$Col <- (rbPal(10)[as.numeric(cut(USmelanoma$mortality,breaks = 10))])
map("state",xlim=c(-135,-65))
points(-USmelanoma$longitude,USmelanoma$latitude,col=USmelanoma$Col,asp=1.5,pch=19,cex=1.2)
legend("topleft",title="Decile",legend=quantile(USmelanoma$mortality,
        seq(0.1,1,l=10)),col =rbPal(10),pch=15,cex=1.,box.col = NA)
```

```{r,fig.width=12,fig.height=10,fig.align='center',message=FALSE,warning=FALSE}
states <- map("state", plot = FALSE, fill = TRUE)
IDs <- sapply(strsplit(states$names, ":"), function(x) x[1])
rownames(USmelanoma) <- tolower(rownames(USmelanoma))

us1 <- map2SpatialPolygons(states, IDs=IDs,proj4string = CRS("+proj=longlat +datum=WGS84"))
us2 <- SpatialPolygonsDataFrame(us1, USmelanoma)

col <- colorRampPalette(c('blue', 'gray80','red'))

spplot(us2, "mortality", col.regions = col(200),
       par.settings = list(axis.line = list(col =  'transparent')),
       main="Map of the US showing malignant melanoma mortality rates")
```

Packages for Spatial Regression / Geostatistics / Spatial Point Pattern methods 

* `sp`, `maptools`, `spatstat`
* `maps`

```{r,eval=FALSE}
install.packages(c("sp","maptools","spatstat","maps"))
```

```{r, message=FALSE,warning=FALSE, fig.align='center'}
library(maps)
```

Basic syntax

```{r, message=FALSE,warning=FALSE, fig.align='center'}
map(database = "world",regions=".")
```

Databases are available for US, France, Italy and New Zealand. For other countries, you need to import a database with the corresponding map.

```{r, message=FALSE,warning=FALSE, fig.align='center'}
map(database = "usa")
map("state")
```

`ggmap` offers plotting capabilities like `ggplot2`

```{r,message=FALSE,warning=FALSE, fig.align='center'}
library(ggmap)
geocode("Bilbao, Spain")
```


```{r,eval=FALSE,echo=FALSE,message=FALSE}
library(knitr)
purl("Ch1.Rmd",output="Ch1.R", documentation = 0)
```


